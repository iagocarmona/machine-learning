{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformando as variáveis categóricas em numéricas. Trocando os atributos da classe ` class` de e -> `0` e p -> `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dados/agaricus_lepiota_small_c.csv')\n",
    "\n",
    "# Separando variáveis dependentes e independentes\n",
    "y = df[['class']].values.ravel()\n",
    "X = df.drop(['class', 'stalk-root'], axis=1)\n",
    "\n",
    "# Transformando coluna \"class\" de e -> 0 e p -> 1\n",
    "y = np.where(y == 'e', 0, 1)\n",
    "\n",
    "# Transformando todas as variáveis categóricas em numéricas\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('oe', OrdinalEncoder(), X.columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Aplicando a transformação em todas as colunas\n",
    "X_oe = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando o desempenho do classificador k-nn com validação cruzada de 2 níveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.87, max: 0.94, avg +- std: 0.90+-0.02\n"
     ]
    }
   ],
   "source": [
    "# Separando os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_oe, y, test_size=0.3, random_state=42)\n",
    "\n",
    "k1 = 10 #controla o número de vias da validação cruzada para estimar o desempenho do modelo\n",
    "k2 = 5 #controla o número de vida da validação cruzada para otimização de hiperparametros\n",
    "\n",
    "# Definindo a métrica personalizada para acurácia da classe positiva (poisonous)\n",
    "def accuracy_positive_class(y_true, y_pred):\n",
    "    positive_indices = y_true == 'poisonous'\n",
    "    return accuracy_score(y_true[positive_indices], y_pred[positive_indices])\n",
    "\n",
    "#usar o protocolo de validação cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=k1, shuffle=True, random_state=1)\n",
    "\n",
    "acuracias = []\n",
    "\n",
    "#a função split retorna os índices das instâncias que devem ser usadas para o treinamento e o teste.\n",
    "for idx_treino, idx_teste in skf.split(X, y):\n",
    "    \n",
    "    #extrair as instâncias de treinamento de acordo com os índices fornecidos pelo skf.split\n",
    "    X_treino = X_oe[idx_treino]\n",
    "    y_treino = y[idx_treino]\n",
    "    \n",
    "    #extrair as instâncias de teste de acordo com os índices fornecidos pelo skf.split\n",
    "    X_teste = X_oe[idx_teste]\n",
    "    y_teste = y[idx_teste]\n",
    "    \n",
    "    #colocar todas as variáveis na mesma escala, usando o conjunto de treinamento para calcular os parâmetros da escala\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_treino)\n",
    "    X_treino = ss.transform(X_treino)\n",
    "    X_teste = ss.transform(X_teste)\n",
    "    \n",
    "    #combinações de parametros otimizar. Aqui estamos apenas otimizando o número de vizinhos mais próximos para o knn (k).\n",
    "    #Entretanto, podemos colocar todos os valores de todos os parametros. O sklearn se encarrega de gerar todas as combinações.\n",
    "    params = {'n_neighbors' : range(1,30,2)}\n",
    "    #instanciar um KNN com parametros padrão\n",
    "    knn = KNeighborsClassifier()\n",
    "    #instanciar um GridSearchCV com k2 vias.\n",
    "    knn = GridSearchCV(knn, params, cv=StratifiedKFold(n_splits=k2), scoring=make_scorer(accuracy_positive_class))\n",
    "    #realizar a otimização dos hiperparâmetros e treinar o modelo final com a melhor combinação de hiperparametros com todos os dados de treinamento\n",
    "    knn.fit(X_treino, y_treino)\n",
    "    \n",
    "    #calcular a acurácia no conjunto de testes desta iteração e salvar na lista.\n",
    "    acuracias.append(accuracy_score(y_teste, knn.predict(X_teste)))\n",
    "    \n",
    "#calcular as estatísticas da validação cruzada. Estas estatísticas nos dão uma confiança que, na média, este é o desempenho esperado\n",
    "#do classificador no mundo real.\n",
    "accs_knn = acuracias\n",
    "print(\"min: %.2f, max: %.2f, avg +- std: %.2f+-%.2f\" % (min(acuracias), max(acuracias), np.mean(acuracias), np.std(acuracias)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando desempenho do classificador SVM usando validação cruzada em 2 níveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfab369e0b114b2c9849f15f29192397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds avaliados:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: 0.90 +- 0.01, min: 0.88, max: 0.91\n"
     ]
    }
   ],
   "source": [
    "#Cs e gammas são listas com os valores a serem avaliados para os respectivos parâmetros.\n",
    "def selecionar_melhor_svm(Cs, gammas, X_treino : np.ndarray, X_val : np.ndarray, \n",
    "                          y_treino : np.ndarray, y_val : np.ndarray, n_jobs=4):\n",
    "    \n",
    "    def treinar_svm(C, gamma, X_treino, X_val, y_treino, y_val):\n",
    "        svm = SVC(C=C, gamma=gamma)\n",
    "        svm.fit(X_treino, y_treino)\n",
    "        pred = svm.predict(X_val)\n",
    "        return accuracy_score(y_val, pred)\n",
    "    \n",
    "    #gera todas as combinações de parametros C e gamma, de acordo com as listas de valores recebidas por parametro.\n",
    "    #Na prática faz o produto cartesiano entre Cs e gammas.\n",
    "    combinacoes_parametros = list(itertools.product(Cs, gammas))\n",
    "    \n",
    "    #Treinar modelos com todas as combinações de C e gamma\n",
    "    acuracias_val = Parallel(n_jobs=n_jobs)(delayed(treinar_svm)\n",
    "                                       (c, g, X_treino, X_val, y_treino, y_val) for c, g in combinacoes_parametros)       \n",
    "    \n",
    "    melhor_val = max(acuracias_val)\n",
    "    #Encontrar a combinação que levou ao melhor resultado no conjunto de validação\n",
    "    melhor_comb = combinacoes_parametros[np.argmax(acuracias_val)]   \n",
    "    melhor_c = melhor_comb[0]\n",
    "    melhor_gamma = melhor_comb[1]\n",
    "    \n",
    "    #Treinar uma SVM com todos os dados de treino e validação usando a melhor combinação de C e gamma.\n",
    "    svm = SVC(C=melhor_c, gamma=melhor_gamma)\n",
    "    svm.fit(np.vstack((X_treino, X_val)), [*y_treino, *y_val])\n",
    "\n",
    "    return svm, melhor_comb, melhor_val\n",
    "\n",
    "#Implementa a validação cruzada para avaliar o desempenho da SVM na base de dados com as instâncias X e as saídas y.\n",
    "#cv_splits indica o número de partições que devem ser criadas.\n",
    "#Cs é a lista com os valores C que devem ser avaliados na busca exaustiva de parametros para a SVM.\n",
    "#gammas s é a lista com os valores gamma que devem ser avaliados na busca exaustiva de parametros para a SVM.\n",
    "def do_cv_svm(X, y, cv_splits, Cs=[1], gammas=['scale']):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    acuracias = []\n",
    "    \n",
    "    pgb = tqdm(total=cv_splits, desc='Folds avaliados')\n",
    "    \n",
    "    for treino_idx, teste_idx in skf.split(X, y):\n",
    "\n",
    "        X_treino = X[treino_idx]\n",
    "        y_treino = y[treino_idx]\n",
    "\n",
    "        X_teste = X[teste_idx]\n",
    "        y_teste = y[teste_idx]\n",
    "\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, stratify=y_treino, test_size=0.2, random_state=1)\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X_treino)\n",
    "        X_treino = ss.transform(X_treino)\n",
    "        X_teste = ss.transform(X_teste)\n",
    "        X_val = ss.transform(X_val)\n",
    "\n",
    "        svm, _, _ = selecionar_melhor_svm(Cs, gammas, X_treino, X_val, y_treino, y_val)\n",
    "        pred = svm.predict(X_teste)\n",
    "\n",
    "        acuracias.append(accuracy_score(y_teste, pred))\n",
    "        \n",
    "        pgb.update(1)\n",
    "        \n",
    "    pgb.close()\n",
    "    \n",
    "    return acuracias\n",
    "\n",
    "def calcular_estatisticas(resultados):\n",
    "    return np.mean(resultados), np.std(resultados), np.min(resultados), np.max(resultados)\n",
    "\n",
    "def imprimir_estatisticas(resultados):\n",
    "    media, desvio, mini, maxi = calcular_estatisticas(resultados)\n",
    "    print(\"Resultados: %.2f +- %.2f, min: %.2f, max: %.2f\" % (media, desvio, mini, maxi))\n",
    "\n",
    "\n",
    "accs_svm = do_cv_svm(X_oe, y, 10, Cs=[1, 10, 100, 1000], gammas=['scale', 'auto', 2e-2, 2e-3, 2e-4])\n",
    "imprimir_estatisticas(accs_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazendo teste da hipótese nula (pelo Teste-T) para verificar se os resultados obtidos com o KNN e com o SVM são estatisticamente diferentes com 95% de confiança. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O p-valor foi 0.58. A diferença entre os classificadores não é significativa.\n"
     ]
    }
   ],
   "source": [
    "media_knn, std_knn, _, _ = calcular_estatisticas(accs_knn)\n",
    "media_svm, std_svm, _, _ = calcular_estatisticas(accs_svm)\n",
    "\n",
    "#calcular o pvalor usando o teste t de Student para duas amostras independentes\n",
    "_, pvalor = ttest_ind_from_stats(media_knn, std_knn, len(accs_knn), media_svm, std_svm, len(accs_svm))\n",
    "\n",
    "if pvalor < 0.05:\n",
    "    print(\"O p-valor foi %.2f. A diferença entre os classificadores é significativa.\" % pvalor)\n",
    "else :\n",
    "    print(\"O p-valor foi %.2f. A diferença entre os classificadores não é significativa.\" % pvalor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Você usaria algum classificador que criou para decidir se comeria ou não um cogumelo classificado por ele? Justifique usando o desempenho obtido e o resultado do teste de hipótese. Esta resposta deve estar no final do caderno jupyter, após a análise estatística.\n",
    "\n",
    "- Considerando que ambos os classificadores tiveram um bom desempenho alcançando até 90% de acurácia, eu ainda teria um pouco de receio em comer algum cogumelo baseado nos resultados dos classificadores. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
